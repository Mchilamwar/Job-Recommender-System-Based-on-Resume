{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a6a58cf",
   "metadata": {},
   "source": [
    "## Recommendation of Job Based on Resume Skills\n",
    "### Flow of Execution\n",
    "* Import Of Resume in PDF/Word format\n",
    "* Cleaning/Skills Extraction based on NlP\n",
    "* RealTime Scrapping Jobs From <b>Indeed.com</b> based on Skill Set\n",
    "* Cleaning Job data and Storing In Data Frame\n",
    "* Vectorization/Embedding of Job Description using Word2Vec transfer Learning Model\n",
    "* Vectorization/Embedding of Resume text using Word2Vec\n",
    "* Calculating cosine Similarity Between Both Resume and Job Descriptions\n",
    "* Suggesting Jobs Based on Similarity Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a40dfe7",
   "metadata": {},
   "source": [
    "### Resume Import , Cleaning,Extraction Of Skills\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "735d671b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6567784",
   "metadata": {},
   "source": [
    "#### Importing resume in pdf and cleaning text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ca9e416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pdf text Extractor\n",
    "def pdf_reader(path):\n",
    "    import PyPDF2\n",
    "    file=open(path,'rb')\n",
    "    text=[]\n",
    "    pdf=PyPDF2.PdfFileReader(file)\n",
    "    \n",
    "    for i in range(pdf.numPages):\n",
    "        page=pdf.getPage(i)\n",
    "        page_text=page.extractText()\n",
    "        text.append(page_text)\n",
    "    \n",
    "    file.close()\n",
    "    return text\n",
    "\n",
    "# Clean Resume\n",
    "\n",
    "\n",
    "def resume_clean(inp_pdf_text):\n",
    "    import re\n",
    "    return_list=[]\n",
    "    for inp_text in inp_pdf_text:\n",
    "        sub=re.sub('\\n+','',inp_text) #remove \\n\n",
    "        sub=re.sub(r'\\S*.\\S*\\/[^\\s]+',' ',sub) #remove links\n",
    "        sub=re.sub(r'\\S*@[^\\s]+',' ',sub) # remove Email\n",
    "        sub=re.sub(r'[^ a-z A-Z]',' ',sub) #Remove numbers\n",
    "        sub=re.sub(r' +',' ',sub) #remove spaces\n",
    "        return_list.append(sub)\n",
    "    return return_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32d924dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_text=pdf_reader('D:\\\\IVY Batches\\\\CV\\\\Fresher Sample Resume\\\\Fresher Sample Resume\\\\SujathaAmbati - Resume.pdf')\n",
    "pdf_text=resume_clean(pdf_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66540206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdf_text\n",
    "final_text=pdf_text[0]+pdf_text[1]\n",
    "# final_text=final_text.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df89af0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a22b4221",
   "metadata": {},
   "source": [
    "#### POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9f61893",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "from nltk.tag import perceptron\n",
    "tokens=word_tokenize(final_text)\n",
    "pos_tokens=nltk.pos_tag(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5bd7bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_text=' '.join([i[0] for i in pos_tokens if i[1] in ('NNP')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a34a3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction._stop_words import ENGLISH_STOP_WORDS\n",
    "cvec=TfidfVectorizer(stop_words=ENGLISH_STOP_WORDS)\n",
    "\n",
    "x=cvec.fit_transform([ner_text])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beed6759",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "437f384e",
   "metadata": {},
   "source": [
    "#### Skills Extraction from Resume text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cd77f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('skills.pkl','rb') as file:\n",
    "    sk=pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "557fa80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def skill_extract(resume_text,sample_skills):\n",
    "    import nltk\n",
    "    tokens=nltk.word_tokenize(resume_text)\n",
    "    skill_tokens=list(map(' '.join,nltk.everygrams(tokens,1,3)))\n",
    "    ret_skills=[]\n",
    "    for i in skill_tokens:\n",
    "        if i.lower() in sample_skills:\n",
    "            ret_skills.append(i.lower())\n",
    "        else:pass\n",
    "    \n",
    "    return list(set(ret_skills))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a67fe90",
   "metadata": {},
   "outputs": [],
   "source": [
    "scrap_skills=skill_extract(final_text,sk) # Skills to scrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1cc3c35b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sql',\n",
       " 'statistics',\n",
       " 'python',\n",
       " 'data',\n",
       " 'excel',\n",
       " 'tableau',\n",
       " 'c',\n",
       " 'analysis',\n",
       " 'visualization',\n",
       " 'machine learning',\n",
       " 'power bi']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scrap_skills"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc60db9b",
   "metadata": {},
   "source": [
    "#### Final Text generaion for Vectorization\n",
    "* Final Text generation removes all entities like Person,Language,Country,Event etc which does not relates with Job Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f4e922f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import en_core_web_trf\n",
    "spa=spacy.load('en_core_web_trf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64812ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec_text(final_text):\n",
    "    import re\n",
    "    ner=spa(final_text)\n",
    "    final_text=final_text.lower()\n",
    "    for i in ner.ents:\n",
    "        if i.label_ in ['GPE','PERSON','ORG','LOC','LANGUAGE','EVENT','WORK_OF_ART','DATE','TIME']:\n",
    "            final_text=final_text.replace(i.text.lower(),' ')\n",
    "    \n",
    "    final_text=re.sub(r'\\b\\w{1}\\b',' ',final_text)\n",
    "    final_text=re.sub(r' +',' ',final_text)\n",
    "    \n",
    "    return final_text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2770bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_to_vectorize=vec_text(final_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "90e85e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_to_vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa9feb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44bb8e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f6af6b2c",
   "metadata": {},
   "source": [
    "## Job-Scrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "512852d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Job Scrapping\n",
    "# #################################################\n",
    "def description_scrap(titles):\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    Description=[]\n",
    "    for title in titles:\n",
    "        for pages in [0,10,20]:\n",
    "            link='https://in.indeed.com/jobs?q={}&start={}'.format(title,pages)\n",
    "\n",
    "            req=requests.get(link)\n",
    "\n",
    "            bs=BeautifulSoup(req.content,'lxml')\n",
    "\n",
    "            # Getting Job Titles\n",
    "\n",
    "            job_div=bs.find_all('div',class_='job_seen_beacon')\n",
    "\n",
    "            # Getting Job Description        \n",
    "\n",
    "\n",
    "            for i in job_div:\n",
    "                description=i.find_all('table',class_='jobCardShelfContainer')\n",
    "                for j in description:\n",
    "                    snippet=j.find('tr',class_='underShelfFooter').find_all('div',class_='job-snippet')\n",
    "                    temp_str=''\n",
    "                    for k in snippet:\n",
    "                        lists=k.find_all('li')\n",
    "                        for l in lists:\n",
    "                            temp_str=temp_str+' '+l.text\n",
    "                    Description.append(temp_str)\n",
    "    \n",
    "    return Description\n",
    "\n",
    "# #############################################################\n",
    "\n",
    "def job_scrap(titles):\n",
    "    \n",
    "    from bs4 import BeautifulSoup\n",
    "    import requests\n",
    "    titles_show=[]\n",
    "    company=[]\n",
    "    location=[]\n",
    "    salary=[]\n",
    "    string=''\n",
    "    for title in titles:\n",
    "        for i in [0,10,20]:\n",
    "            link='https://in.indeed.com/jobs?q={}&start={}'.format(title,i)\n",
    "\n",
    "            req=requests.get(link)\n",
    "            bs=BeautifulSoup(req.content,'lxml')\n",
    "\n",
    "            for j in bs.find_all('h2',class_='jobTitle'):\n",
    "                string=j.text\n",
    "                titles_show.append(string)\n",
    "\n",
    "\n",
    "            for k in bs.find_all('span',class_='companyName'):\n",
    "                company.append(k.text)\n",
    "\n",
    "            for l in bs.find_all('div',class_='companyLocation'):\n",
    "                location.append(l.text)\n",
    "\n",
    "\n",
    "            job_div=bs.find_all('div',class_='job_seen_beacon')\n",
    "\n",
    "            for i in job_div:\n",
    "                table=i.find_all('table',class_='jobCard_mainContent')\n",
    "                for j in table:\n",
    "                    span=j.find('td').find_all('span')   \n",
    "                    salary.append(span[-1].text)\n",
    "        \n",
    "    \n",
    "    return titles_show,company,location,salary\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ##################################################################################\n",
    "# Link retrival\n",
    "def link_retriver(title):\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    append_link=[]\n",
    "    # All possible links retrival\n",
    "    for pages in [0,10,20]:\n",
    "        link='https://in.indeed.com/jobs?q={}&start={}'.format(title,pages)\n",
    "\n",
    "        req=requests.get(link)\n",
    "        bs=BeautifulSoup(req.content,'lxml')\n",
    "\n",
    "        # Getting Job Titles\n",
    "        job_div=bs.find('div',id='mosaic-provider-jobcards')\n",
    "\n",
    "        # for i in job_div:\n",
    "        #     print(i.find_all('a'))\n",
    "        \n",
    "        final_link=''\n",
    "        for i in job_div.find_all('a')[1:]:\n",
    "            link='https://www.indeed.com'+i.get('href')\n",
    "            final_link=final_link+'  '+link\n",
    "        \n",
    "        append_link.append(final_link)\n",
    "    \n",
    "    return append_link\n",
    "\n",
    "# ##################################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df5819b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "title,company,location,salary=job_scrap(scrap_skills)\n",
    "description=description_scrap(scrap_skills)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798e8117",
   "metadata": {},
   "source": [
    "#### Storing Scrapped Jobs in Dataframe and cleaning Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "abb611c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>salary</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>newTeam Lead - Data Analyst</td>\n",
       "      <td>ICICI Bank Ltd</td>\n",
       "      <td>Mumbai, Maharashtra</td>\n",
       "      <td>₹15,00,000 a year</td>\n",
       "      <td> Provide end to end analytical support for t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>newMS SQL Developer</td>\n",
       "      <td>Dusane Infotech Pvt Ltd</td>\n",
       "      <td>Thane, Maharashtra</td>\n",
       "      <td>₹25,000 - ₹40,000 a month</td>\n",
       "      <td>1.Designing database tables and structures. 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>newSQL Developer</td>\n",
       "      <td>MaaxtreeM</td>\n",
       "      <td>Hyderabad, Telangana</td>\n",
       "      <td>₹19,413 - ₹88,072 a month</td>\n",
       "      <td>Experience : Freshers/experience of 1 to 5 ye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>newSQL Developer</td>\n",
       "      <td>d-insights pvt ltd</td>\n",
       "      <td>Mumbai, Maharashtra</td>\n",
       "      <td>₹2,00,000 - ₹5,00,000 a year</td>\n",
       "      <td>Knowledge on data bases, preferably oracle/My...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SQL Developer</td>\n",
       "      <td>Premade Innovations Pvt Ltd</td>\n",
       "      <td>Pune, Maharashtra</td>\n",
       "      <td>₹15,000 - ₹20,000 a month</td>\n",
       "      <td>Candidate must have proven years of experienc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         title                      company  \\\n",
       "0  newTeam Lead - Data Analyst               ICICI Bank Ltd   \n",
       "1          newMS SQL Developer      Dusane Infotech Pvt Ltd   \n",
       "2             newSQL Developer                    MaaxtreeM   \n",
       "3             newSQL Developer           d-insights pvt ltd   \n",
       "4                SQL Developer  Premade Innovations Pvt Ltd   \n",
       "\n",
       "               location                        salary  \\\n",
       "0   Mumbai, Maharashtra             ₹15,00,000 a year   \n",
       "1    Thane, Maharashtra     ₹25,000 - ₹40,000 a month   \n",
       "2  Hyderabad, Telangana     ₹19,413 - ₹88,072 a month   \n",
       "3   Mumbai, Maharashtra  ₹2,00,000 - ₹5,00,000 a year   \n",
       "4     Pune, Maharashtra     ₹15,000 - ₹20,000 a month   \n",
       "\n",
       "                                         description  \n",
       "0    Provide end to end analytical support for t...  \n",
       "1   1.Designing database tables and structures. 2...  \n",
       "2   Experience : Freshers/experience of 1 to 5 ye...  \n",
       "3   Knowledge on data bases, preferably oracle/My...  \n",
       "4   Candidate must have proven years of experienc...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# JOB dataframe\n",
    "import pandas as pd\n",
    "\n",
    "Job_df=pd.DataFrame({'title':title,'company':company,'location':location,'salary':salary,'description':description})\n",
    "Job_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c671a621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning Description removing non usable characters\n",
    "def description_clean(text):\n",
    "    import re\n",
    "    text=re.sub('[^a-z A-Z]',' ',text)\n",
    "    text=re.sub(' +',' ',text)\n",
    "    return text.strip().lower()\n",
    "\n",
    "# Salary Section have some junk values which are not salary amount so removing them\n",
    "\n",
    "def salary_clean(text):\n",
    "    if '₹' in text:\n",
    "        return text\n",
    "    else:\n",
    "        return \"Not Available\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "25be8557",
   "metadata": {},
   "outputs": [],
   "source": [
    "Job_df['salary']=Job_df['salary'].apply(salary_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37720e7a",
   "metadata": {},
   "source": [
    "#### To Vectorize text/description generation \n",
    "* generation of Final cleaned text of description to be vectorized using word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea395841",
   "metadata": {},
   "outputs": [],
   "source": [
    "Job_df['to_vectorize']=Job_df['title']+' '+Job_df['description']\n",
    "Job_df['to_vectorize']=Job_df['to_vectorize'].apply(description_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1111fc2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a40c9b53",
   "metadata": {},
   "source": [
    "### Vectorization/Embedding of Resume and Job description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff48747f",
   "metadata": {},
   "source": [
    "#### CountVectorizing job description text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "026f6938",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction._stop_words import ENGLISH_STOP_WORDS\n",
    "cnt=CountVectorizer(stop_words=ENGLISH_STOP_WORDS)\n",
    "X=cnt.fit_transform(Job_df['to_vectorize']).toarray() #count vectorizing\n",
    "\n",
    "features=cnt.get_feature_names() #feature names\n",
    "\n",
    "job_vectors_df=pd.DataFrame(X,columns=features) # vectors dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a96fd1",
   "metadata": {},
   "source": [
    "#### Word Embedding using Word2vec Google News 300 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e1475f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import keyedvectors\n",
    "\n",
    "wordvec=keyedvectors.load_word2vec_format('D:\\\\IVY Batches\\\\ML DL NLP\\\\word2vec\\\\GoogleNews-vectors-negative300.bin.gz',binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fdd3c8",
   "metadata": {},
   "source": [
    "#### Creating Dataframe of Embedded description word vectors\n",
    "* creating an temporary dataframe to store the embedding results for each of Job description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c99f91e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "embedd_vectors=pd.DataFrame() #empty dataframe\n",
    "wordvec_keys=list(wordvec.key_to_index.keys()) #Keys in word2vec model\n",
    "\n",
    "for i in range(job_vectors_df.shape[0]):\n",
    "    word_bool=list(job_vectors_df.iloc[i,:].values!= 0)\n",
    "    sent_vector=np.zeros(300)\n",
    "    words=[val for val,bools in zip(features,word_bool) if bools ]\n",
    "    \n",
    "    for word in words:\n",
    "        if word in wordvec_keys:\n",
    "            sent_vector=sent_vector+wordvec[word]\n",
    "        else:pass\n",
    "    \n",
    "    embedd_vectors=embedd_vectors.append(pd.DataFrame([sent_vector]))\n",
    "        \n",
    "embedd_vectors.reset_index(drop=True,inplace=True)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b76679",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f3da95a",
   "metadata": {},
   "source": [
    "#### Vectorization/Embedding of Resume Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5f09a36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "count=CountVectorizer(stop_words=ENGLISH_STOP_WORDS)\n",
    "resume_vec_features=count.fit([text_to_vectorize]).get_feature_names()\n",
    "\n",
    "resume_wordvec=np.zeros(300)\n",
    "\n",
    "for i in resume_vec_features:\n",
    "    if i in wordvec_keys:\n",
    "        resume_wordvec=resume_wordvec+wordvec[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8a6ddf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "84c5f09d",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "### Calculaing Cosine Similarity between Resume and Job Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "67643a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "similarity=pd.DataFrame() # Creating Sample dataframe to store Similarity Values Temporarily\n",
    "\n",
    "for i in range(embedd_vectors.shape[0]):\n",
    "    to_append=cosine_similarity(resume_wordvec.reshape(1,-1),embedd_vectors.iloc[i].values.reshape(1,-1))\n",
    "    \n",
    "    similarity=similarity.append(pd.DataFrame(to_append))\n",
    "\n",
    "similarity.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "80c06977",
   "metadata": {},
   "outputs": [],
   "source": [
    "Job_df['Similarity_with_resume']=similarity # Appending Similarity to Job Dataframe for recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19eadf66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "da0d1a0b",
   "metadata": {},
   "source": [
    "### Showing Reccomendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7dcec68e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>salary</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>newData Entry Operator</td>\n",
       "      <td>Three Ess Computer Services (I) Pvt. Ltd.</td>\n",
       "      <td>Mumbai, Maharashtra</td>\n",
       "      <td>₹10,000 - ₹13,000 a month</td>\n",
       "      <td>Proficiency in data capturing and MS Office (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>Data Entry Operator</td>\n",
       "      <td>XLNC</td>\n",
       "      <td>Ghatkopar, Mumbai, Maharashtra</td>\n",
       "      <td>₹13,800 - ₹18,500 a month</td>\n",
       "      <td>Job Role- KYC Document verification. \\*We req...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>newSenior Research Executive - Instrumental Ev...</td>\n",
       "      <td>L'Oreal</td>\n",
       "      <td>Mumbai, Maharashtra</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>Exposure to any visualization tool (including...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>newData Entry Operator</td>\n",
       "      <td>Growit India Private Limited (www.thegrowit.com)</td>\n",
       "      <td>Surat, Gujarat</td>\n",
       "      <td>₹10,000 - ₹15,000 a month</td>\n",
       "      <td>Job Role- KYC Document verification. \\*We req...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>newInternational BPO</td>\n",
       "      <td>Epicenter Technologies Pvt. Ltd</td>\n",
       "      <td>Remote in Bhayandar, Mumbai, Maharashtra</td>\n",
       "      <td>₹15,000 - ₹25,000 a month</td>\n",
       "      <td>Good typing ability (minimum 40 WPM). Minimum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>newHIRING Machine Learning_Permanent Work from...</td>\n",
       "      <td>Net Connect</td>\n",
       "      <td>Remote in Mumbai, Maharashtra</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>Must have strong experience with statistical ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>newAssociate , Content Strategy &amp; Analysis</td>\n",
       "      <td>Netflix</td>\n",
       "      <td>Mumbai, Maharashtra</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>Candidate must have excellent subjective know...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>Consultant/AM- AI-Machine Learning - Mumbai</td>\n",
       "      <td>KPMG</td>\n",
       "      <td>Mumbai, Maharashtra</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>The Test Engineering Services Automation Deve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>newData Entry Operator</td>\n",
       "      <td>Growit India Private Limited (www.thegrowit.com)</td>\n",
       "      <td>Surat, Gujarat</td>\n",
       "      <td>₹10,000 - ₹15,000 a month</td>\n",
       "      <td>Well versed with Google sheets &amp; advance exce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>Executive Assistant To Leadership</td>\n",
       "      <td>NISA INDUSTRIAL SERVICES PVT. LTD.</td>\n",
       "      <td>Andheri, Mumbai, Maharashtra</td>\n",
       "      <td>₹2,50,000 - ₹5,00,000 a year</td>\n",
       "      <td>Ability to read and write English. Desire to ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "145                             newData Entry Operator   \n",
       "148                                Data Entry Operator   \n",
       "391  newSenior Research Executive - Instrumental Ev...   \n",
       "150                             newData Entry Operator   \n",
       "191                               newInternational BPO   \n",
       "425  newHIRING Machine Learning_Permanent Work from...   \n",
       "52          newAssociate , Content Strategy & Analysis   \n",
       "421        Consultant/AM- AI-Machine Learning - Mumbai   \n",
       "203                             newData Entry Operator   \n",
       "205                  Executive Assistant To Leadership   \n",
       "\n",
       "                                              company  \\\n",
       "145         Three Ess Computer Services (I) Pvt. Ltd.   \n",
       "148                                              XLNC   \n",
       "391                                           L'Oreal   \n",
       "150  Growit India Private Limited (www.thegrowit.com)   \n",
       "191                   Epicenter Technologies Pvt. Ltd   \n",
       "425                                       Net Connect   \n",
       "52                                            Netflix   \n",
       "421                                              KPMG   \n",
       "203  Growit India Private Limited (www.thegrowit.com)   \n",
       "205                NISA INDUSTRIAL SERVICES PVT. LTD.   \n",
       "\n",
       "                                     location                        salary  \\\n",
       "145                       Mumbai, Maharashtra     ₹10,000 - ₹13,000 a month   \n",
       "148            Ghatkopar, Mumbai, Maharashtra     ₹13,800 - ₹18,500 a month   \n",
       "391                       Mumbai, Maharashtra                 Not Available   \n",
       "150                            Surat, Gujarat     ₹10,000 - ₹15,000 a month   \n",
       "191  Remote in Bhayandar, Mumbai, Maharashtra     ₹15,000 - ₹25,000 a month   \n",
       "425             Remote in Mumbai, Maharashtra                 Not Available   \n",
       "52                        Mumbai, Maharashtra                 Not Available   \n",
       "421                       Mumbai, Maharashtra                 Not Available   \n",
       "203                            Surat, Gujarat     ₹10,000 - ₹15,000 a month   \n",
       "205              Andheri, Mumbai, Maharashtra  ₹2,50,000 - ₹5,00,000 a year   \n",
       "\n",
       "                                           description  \n",
       "145   Proficiency in data capturing and MS Office (...  \n",
       "148   Job Role- KYC Document verification. \\*We req...  \n",
       "391   Exposure to any visualization tool (including...  \n",
       "150   Job Role- KYC Document verification. \\*We req...  \n",
       "191   Good typing ability (minimum 40 WPM). Minimum...  \n",
       "425   Must have strong experience with statistical ...  \n",
       "52    Candidate must have excellent subjective know...  \n",
       "421   The Test Engineering Services Automation Deve...  \n",
       "203   Well versed with Google sheets & advance exce...  \n",
       "205   Ability to read and write English. Desire to ...  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Job_df.sort_values(by='Similarity_with_resume',ascending=False).head(10)[['title','company','location','salary','description']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01478342",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fe34a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
